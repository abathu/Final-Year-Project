{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T15:38:46.815066Z",
     "start_time": "2024-04-10T15:38:45.178277Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from tqdm import tqdm  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T15:38:46.816677Z",
     "start_time": "2024-04-10T15:38:46.815237Z"
    }
   },
   "outputs": [],
   "source": [
    "directories = [r\"C:\\Users\\abathur\\Desktop\\tweet_01\",r\"C:\\Users\\abathur\\Desktop\\tweet_02\",r\"C:\\Users\\abathur\\Desktop\\tweet_03\",\n",
    "               r\"C:\\Users\\abathur\\Desktop\\2023_01_done\",r\"C:\\Users\\abathur\\Desktop\\2023_3_done\",r\"C:\\Users\\abathur\\Desktop\\2023_4\",\n",
    "               r\"C:\\Users\\abathur\\Desktop\\2023_5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing directories:   0%|          | 0/7 [00:00<?, ?it/s]\n",
      "Reading files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                 \u001b[A\n",
      "Reading files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                 \u001b[A\n",
      "Reading files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                 \u001b[A\n",
      "Reading files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                 \u001b[A\n",
      "Reading files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                 \u001b[A\n",
      "Reading files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                 \u001b[A\n",
      "Reading files: 0it [00:00, ?it/s]\u001b[A\n",
      "Processing directories: 100%|██████████| 7/7 [00:00<00:00, 816.88it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m         dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Concatenate all DataFrames in the list into a single DataFrame\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m final_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dfs, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:372\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    370\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    373\u001b[0m     objs,\n\u001b[1;32m    374\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m    375\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[1;32m    376\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[1;32m    377\u001b[0m     keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[1;32m    378\u001b[0m     levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[1;32m    379\u001b[0m     names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[1;32m    380\u001b[0m     verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[1;32m    381\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    382\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    383\u001b[0m )\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:429\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    426\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store dataframes\n",
    "dfs = []\n",
    "\n",
    "for directory in tqdm(directories, desc=\"Processing directories\"):  # Add tqdm here for directories\n",
    "    # List all CSV files in the directory\n",
    "    csv_files = glob.glob(os.path.join(directory, \"*.csv\"))\n",
    "    \n",
    "    for file in tqdm(csv_files, desc=\"Reading files\", leave=False):  # Add tqdm here for files\n",
    "        df = pd.read_csv(file, header='infer')\n",
    "        # Drop the first row;  DataFrame indices are zero-based, I find the header is appear twice in csv file\n",
    "        df = df.drop(df.index[0])\n",
    "        df = df.dropna(subset=['text'])\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()\n",
    "display (final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = final_df['text']\n",
    "labels = final_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the coefficients\n",
    "def plot_coefficients(classifier, feature_names, top_features=50):\n",
    "    coef = classifier.coef_.ravel()\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "    # Create plot\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    colors = ['red' if c < 0 else 'blue' for c in coef[top_coefficients]]\n",
    "    plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.xticks(np.arange(1, 1 + 2 * top_features), feature_names[top_coefficients], rotation=60, ha='right')\n",
    "    plt.show()\n",
    "\n",
    "# Vectorize text data\n",
    "cv = CountVectorizer()\n",
    "X_train = cv.fit_transform(texts)\n",
    "\n",
    "# Initialize and train the SVM classifier\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_train, labels)\n",
    "\n",
    "# Plot the coefficients of the features\n",
    "plot_coefficients(svm, cv.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The solution look like ungood, tokenzied all word are see reulst again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import capturePPMI\n",
    "from capturePPMI import Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is a typo, this should be a function not attribute, but it can still work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokenzid = Corpus(texts).get_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_text_tokenzid = text_tokenzid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(corrected_text_tokenzid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the coefficients\n",
    "def plot_coefficients(classifier, feature_names, top_features=50):\n",
    "    coef = classifier.coef_.ravel()\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "    # Create plot\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    colors = ['red' if c < 0 else 'blue' for c in coef[top_coefficients]]\n",
    "    plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.xticks(np.arange(1, 1 + 2 * top_features), feature_names[top_coefficients], rotation=60, ha='right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize text data\n",
    "cv = CountVectorizer()\n",
    "\n",
    "# Assuming corrected_text_tokenzid is a list of lists (each inner list is a list of tokens)\n",
    "documents = [\" \".join(doc) for doc in corrected_text_tokenzid]\n",
    "X_train = cv.fit_transform(documents)\n",
    "\n",
    "# Initialize and train the SVM classifier\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_train, labels)\n",
    "\n",
    "# Plot the coefficients of the features\n",
    "plot_coefficients(svm, cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coefficients(svm, cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featues = cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(featues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = cv.get_feature_names_out()\n",
    "coefficients = svm.coef_.ravel()\n",
    "\n",
    "# Pairing coefficients with feature names\n",
    "coefs_with_fns = sorted(zip(coefficients, feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the first 20 elements\n",
    "top_20_coefs_with_fns = coefs_with_fns[:20]\n",
    "\n",
    "# Displaying the top 20 coefficients and their corresponding words\n",
    "print(\"Coefficient\", \"Word\")\n",
    "for coef, word in top_20_coefs_with_fns:\n",
    "    print(f\"{coef:.4f}\", word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the last  elements\n",
    "last_30_coefs_with_fns = coefs_with_fns[-100:]\n",
    "\n",
    "# Displaying the last  coefficients and their corresponding words\n",
    "print(\"Coefficient\", \"Word\")\n",
    "for coef, word in last_30_coefs_with_fns:\n",
    "    print(f\"{coef:.4f}\", word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:49:36.316411Z",
     "start_time": "2024-04-11T20:49:36.159953Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Load coefs_with_fns from the file\n",
    "with open('coefs_with_fns_2023.pkl', 'rb') as file:  # 'rb' denotes 'read binary'\n",
    "    loaded_coefs_with_fns = pickle.load(file)\n",
    "\n",
    "# Verify by printing the first few elements\n",
    "print(\"Coefficient\", \"Word\")\n",
    "for coef, word in loaded_coefs_with_fns[-1000:]:\n",
    "    print(f\"{coef:.4f}\", word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T20:49:50.273494Z",
     "start_time": "2024-04-11T20:49:50.266554Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573178\n"
     ]
    }
   ],
   "source": [
    "print (len(loaded_coefs_with_fns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T21:12:19.777959Z",
     "start_time": "2024-04-11T21:12:19.622258Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Word\n",
      "2.8027 magicalbitch420\n",
      "2.8033 boquetofasshole\n",
      "2.8744 gay19\n",
      "2.9437 furryfando\n",
      "2.9726 assho\n",
      "2.9858 pxdomom\n",
      "3.1660 kacchussy\n",
      "3.2307 gapekeeper85\n",
      "3.2399 cumguzzlernyc\n",
      "4.0072 buynude\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Load coefs_with_fns from the file\n",
    "\n",
    "#\n",
    "# # Verify by printing the first few elements\n",
    "# print(\"Coefficient\", \"Word\")\n",
    "# for coef, word in loaded_coefs_with_fns[-10:]:\n",
    "#     print(f\"{coef:.4f}\", word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T21:11:09.851733Z",
     "start_time": "2024-04-11T21:11:09.733772Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108778\n"
     ]
    }
   ],
   "source": [
    "with open('coefs_with_fns.pkl', 'rb') as file:  # 'rb' denotes 'read binary'\n",
    "    loaded_coefs_with_fns = pickle.load(file)\n",
    "positive_words = [(word,coef)for  coef,word  in loaded_coefs_with_fns if coef > 0]\n",
    "# print(len(positive_words))\n",
    "positive_words_sorted = sorted([(word, coef) for coef, word in loaded_coefs_with_fns if coef > 0], key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T21:11:46.263628Z",
     "start_time": "2024-04-11T21:11:46.260544Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.007200609536313 buynude\n",
      "3.239852589688218 cumguzzlernyc\n",
      "3.2307420747825346 gapekeeper85\n",
      "3.1659887497952677 kacchussy\n",
      "2.985825312166148 pxdomom\n",
      "2.9725705180922053 assho\n",
      "2.943657306516855 furryfando\n",
      "2.8743853994298174 gay19\n",
      "2.803316683892204 boquetofasshole\n",
      "2.8027302655451347 magicalbitch420\n"
     ]
    }
   ],
   "source": [
    "for word ,coef  in positive_words_sorted[:10]:\n",
    "    print(f\"{coef}\", word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T15:40:20.735642Z",
     "start_time": "2024-04-10T15:40:20.733620Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.125900221504561"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs_dict['shit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T15:41:42.362181Z",
     "start_time": "2024-04-10T15:41:42.315954Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T15:41:43.129180Z",
     "start_time": "2024-04-10T15:41:43.127981Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 4 space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norms before calling fill_norms: None\n",
      "Norms after calling fill_norms: [ 5. 10.]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "\n",
    "# Create a mock Word2Vec model with two words \"apple\" and \"banana\" and simple vectors\n",
    "model = KeyedVectors(vector_size=2)\n",
    "model.add_vectors(keys=[\"apple\", \"banana\"], weights=np.array([[3, 4], [6, 8]]))\n",
    "\n",
    "# Before calling fill_norms, the norms are not calculated and stored\n",
    "print(\"Norms before calling fill_norms:\", model.norms)\n",
    "\n",
    "# Call fill_norms with force=False\n",
    "model.fill_norms(force=False)\n",
    "\n",
    "# After calling fill_norms, the norms should be calculated and stored\n",
    "print(\"Norms after calling fill_norms:\", model.norms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
